{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5d61ed",
   "metadata": {},
   "source": [
    "# Image Classification using CNN \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e3e1c",
   "metadata": {},
   "source": [
    "**Implement convolutional neural network (CNN) models with following specifications\n",
    "using TensorFlow for classifying the MNIST dataset. Train the model on the MNIST\n",
    "training set and evaluate its performance on the test set. Write modularized code and\n",
    "call it 3 times and compute the mean of test accuracy for each of the following 3\n",
    "Sequential models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947e7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils,layers,models\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06034066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, 10)\n",
    "#y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba9471",
   "metadata": {},
   "source": [
    "**Model-1: Add a convolution layer with 32 3 × 3 filters with stride 2 and relu\n",
    "activation. Add a maxpooling layer with kernel size 2 × 2 with stride 1. Add a\n",
    "convolution layer with 16 4 × 4 filters with stride 2 and relu activation. Add a\n",
    "maxpooling layer with kernel size 4 × 4 with stride 2. Flatten the output and\n",
    "add a fully connected layer with 8 neurons with relu activation. Add a fully\n",
    "connected layer with 10 neurons and softmax activation. Use Adam optimizer\n",
    "with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "503f3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),strides=(2,2),activation='relu',input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2,2),strides=(1,1)))\n",
    "    model.add(Conv2D(16,kernel_size=(4,4),strides=(2,2),activation='relu'))\n",
    "    model.add(MaxPooling2D((4,4),strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    return score[1]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2858b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4783 - loss: 1.4190\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.5412\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.4396\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8796 - loss: 0.3821\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.3524\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.4415\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5460 - loss: 1.2813\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.4317\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.3347\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.2974\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2584\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2575\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5556 - loss: 1.2660\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.4230\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.3115\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.2711\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.2303\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2950\n",
      "Mean Test Accuracy: 0.9092666705449423\n"
     ]
    }
   ],
   "source": [
    "test_acc1=np.zeros(3)\n",
    "for i in range(3):\n",
    "    test_acc1[i]=model1()\n",
    "mean_test_acc1=sum(test_acc1)/3 \n",
    "print(\"Mean Test Accuracy:\",mean_test_acc1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76d08c",
   "metadata": {},
   "source": [
    "**Model-2: Add a convolution layer with 32 3 × 3 filters with stride 2 and relu\n",
    "activation. Add an average pooling layer with kernel size 2 × 2 with stride 1.\n",
    "Add a convolution layer with 16 4 × 4 filters with stride 2 and relu activation.\n",
    "Add an average pooling layer with kernel size 4 × 4 with stride 2. Flatten the\n",
    "output and add a fully connected layer with 8 neurons with relu activation.\n",
    "Add a fully connected layer with 10 neurons and softmax activation. Use\n",
    "Adam optimizer with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "135aa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D\n",
    "def model2():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),strides=(2,2),activation='relu',input_shape=(28, 28, 1)))\n",
    "    model.add(AveragePooling2D((2,2),strides=(1,1)))\n",
    "    model.add(Conv2D(16,kernel_size=(4,4),strides=(2,2),activation='relu'))\n",
    "    model.add(AveragePooling2D((4,4),strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    return score[1]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f3c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4281 - loss: 1.5894\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.6165\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.4673\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.3968\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.3486\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.3191\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4263 - loss: 1.5874\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.6473\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.5174\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.4228\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.3818\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.4544\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4281 - loss: 1.5669\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.6955\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.4954\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.4070\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.3496\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.3930\n",
      "Mean Test Accuracy: 0.8968666593233744\n"
     ]
    }
   ],
   "source": [
    "test_acc2=np.zeros(3)\n",
    "for i in range(3):\n",
    "    test_acc2[i]=model2()\n",
    "mean_test_acc2=sum(test_acc2)/3 \n",
    "print(\"Mean Test Accuracy:\",mean_test_acc2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28456238",
   "metadata": {},
   "source": [
    "**Model-3: Add a convolution layer with 32 3 × 3 filters with stride 2, relu\n",
    "activation and same padding. Add a maxpooling layer with kernel size 2 × 2\n",
    "with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2 and\n",
    "relu activation. Add a maxpooling layer with kernel size 4 × 4 with stride 2.\n",
    "Flatten the output and add a fully connected layer with 8 neurons with relu\n",
    "activation. Add a fully connected layer with 10 neurons and softmax\n",
    "activation. Use Adam optimizer with batch size 128, learning rate 0.01 and\n",
    "epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76964d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),strides=(2,2),activation='relu',padding='same',input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2,2),strides=(1,1)))\n",
    "    model.add(Conv2D(16,kernel_size=(4,4),strides=(2,2),activation='relu'))\n",
    "    model.add(MaxPooling2D((4,4),strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    return score[1]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d71bfbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4543 - loss: 1.4947\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.5121\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.3906\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.3494\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.3295\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.3704\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 1.4034\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.6303\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.4824\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.4097\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.3802\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.3625\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2313 - loss: 1.8894\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6901 - loss: 0.9073\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.6953\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.6147\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.5639\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 0.5813\n",
      "Mean Test Accuracy: 0.8819999893506368\n"
     ]
    }
   ],
   "source": [
    "test_acc3=np.zeros(3)\n",
    "for i in range(3):\n",
    "    test_acc3[i]=model3()\n",
    "mean_test_acc3=sum(test_acc3)/3 \n",
    "print(\"Mean Test Accuracy:\",mean_test_acc3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813942f",
   "metadata": {},
   "source": [
    "**Model-4: Add a convolution layer with 32 3 × 3 filters with stride 2, relu\n",
    "activation and zero padding. Add a maxpooling layer with kernel size 2 × 2\n",
    "with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2, relu\n",
    "activation and zero padding. Add a maxpooling layer with kernel size 4 × 4\n",
    "with stride 2. Flatten the output and add a fully connected layer with 8 neurons\n",
    "with relu activation. Add a fully connected layer with 10 neurons and softmax\n",
    "-activation. Use Adam optimizer with batch size 128, learning rate 0.01 and\n",
    "epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26b4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ZeroPadding2D\n",
    "def model4():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),strides=(2,2),activation='relu',padding='same',input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2,2),strides=(1,1)))\n",
    "    model.add(Conv2D(16,kernel_size=(4,4),strides=(2,2),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D((4,4),strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    return score[1]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b49ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.8802\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1861\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9564 - loss: 0.1411\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9622 - loss: 0.1214\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.1084\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1295\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6097 - loss: 1.1051\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.2221\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1724\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1391\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.1313\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1712\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5805 - loss: 1.1360\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2820\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.2150\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9410 - loss: 0.1925\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9460 - loss: 0.1723\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2239\n",
      "Mean Test Accuracy: 0.9541999896367391\n"
     ]
    }
   ],
   "source": [
    "test_acc4=np.zeros(3)\n",
    "for i in range(3):\n",
    "    test_acc4[i]=model4()\n",
    "mean_test_acc4=sum(test_acc4)/3 \n",
    "print(\"Mean Test Accuracy:\",mean_test_acc4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f375418",
   "metadata": {},
   "source": [
    "**Using kerastuner to select the best hyperparameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f23edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "def build_model(hp):\n",
    "    model=Sequential()    \n",
    "     \n",
    "    filters = hp.Int('filters', min_value=32, max_value=128, step=32)\n",
    "    kernel_size = hp.Choice('kernel_size', values=[3, 5])\n",
    "    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
    "    pooling_type = hp.Choice('pooling_type', values=['max', 'avg'])\n",
    "    activation_func = hp.Choice('activation_func', values=['relu', 'tanh', 'sigmoid'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(layers.Conv2D(filters, kernel_size, activation=activation_func, input_shape=(28, 28, 1)))\n",
    "    if pooling_type == 'max':       \n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Conv2D(filters*2, kernel_size, activation=activation_func))\n",
    "        model.add(MaxPooling2D((3,3)))               \n",
    "   \n",
    "    if pooling_type == \"avg\":\n",
    "        model.add(AveragePooling2D((2,2)))\n",
    "        model.add(Conv2D(filters*2, kernel_size, activation=activation_func))\n",
    "        model.add(AveragePooling2D((3,3)))       \n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(dense_units, activation=activation_func))   \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db19e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir\\mnist_cnn\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='mnist_cnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de6be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train,\n",
    "             epochs=3,\n",
    "             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f055215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "filters: 96\n",
      "kernel_size: 3\n",
      "dense_units: 128\n",
      "pooling_type: max\n",
      "activation_func: tanh\n",
      "learning_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "for hyperparameter, value in best_hps.values.items():\n",
    "    print(f\"{hyperparameter}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a7ab77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9243 - loss: 0.2436 - val_accuracy: 0.9842 - val_loss: 0.0521\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9859 - loss: 0.0475 - val_accuracy: 0.9868 - val_loss: 0.0423\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.9907 - loss: 0.0316 - val_accuracy: 0.9865 - val_loss: 0.0419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x211aa3d7bd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)    \n",
    "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5d87fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9931333065032959\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b477c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cf0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
